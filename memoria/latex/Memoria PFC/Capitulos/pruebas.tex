
\chapter{Pruebas}

La fase de pruebas permite comprobar la corrección de los algoritmos
de la aplicación y que cada módulo cumple con los requisitos iniciales
planteados.

Cada apartado de este punto se refiere a un tipo de prueba realizado,
como son los tests unitarios, los de carga y los de sistema, además
de haber realizado varios tests con personas físicas.

Debido al ciclo de vida del proyecto, explicado en el apartado Gestión
de tiempo, el desarrollo ha sido un ciclo de vida evolutivo, por lo
que la automatización de pruebas se realizó al final del proyecto,
y no en cada refinamiento del proyecto.


\section{Tests unitarios y cobertura de código}

En estos tests se ha querido comprobar el perfecto funcionamiento
de todas las clases que se mapean en la base de datos, \emph{models},
así como el correcto funcionamiento de los validadores creados para
la correcta comprobación de los formularios,\emph{forms} y la clase
encargada en los emparejamientos de las decisiones, \emph{game}.

Dentro de las pruebas unitarias se realizó pruebas de caja negra,
que sirven para verificar que el item que se está probando, cuando
se dan las entradas apropiadas produce los resultados esperados. Siendo
este tipo de pruebas interesantes para comprobar el funcionamiento
de las interfaces.

Además dentro de las pruebas unitarias, se realizo la cobertura de
código, para comprobar el grado en que el código fuente del programa
ha sido testeado en estas pruebas unitarias, así como la identificación
de código nunca ejecutado.

Todos estos tests se integraron en la plataforma, pudiendose ejecutar
desde ella, como se puede ver en la figura \ref{fig:unit_test}

\begin{figure}[!tbh]
 	\begin{center}
\begin{listing}[style=consola, numbers=none]
$ ./manage.py test
test_answer (test_models.ModelsTestCase) ... ok
test_game_dictador (test_models.ModelsTestCase) ... ok
...
test_requerid_selectField (test_validators.ValidatorTest) ... ok

Module              statements  missing     excluded    branches    partial     coverage
app/game/game       289         73          0           96          16          74%
app/main/views      14          13          0           0           0           7%
app/models          756         60          0           157         5           97%
app/surveys/forms   166         94          4           85          10          48%
app/surveys/utiles  42          23          0           22          7           44%
Total               1267        263         4           360         38          83%
\end{listing}
		 \caption{Resultado de la ejecución de los test unitarios}
 		\label{fig:unit_test}
	 \end{center}
\end{figure}

Pese a no llegar a una cobertura cercana al 100\%, si se analiza mas
detalladamente los ficheros, se puede comprobar que si que se ha testeado
las partes que se pretendía analizar. 


\section{Pruebas de carga}

Este tipo de pruebas sirve para comprobar el rendimiento de la aplicación
ante una carga de trabajo dado, con perspectiva para determinar el
comportamiento de la plataforma web ante un acceso concurrente de
cierto número de usuarios.

Para realizar el acceso concurrente, se utilizo la herramienta JMeter,
que puede realizar todas las conexiones TCP que realizaría un usuario
para contestar a la encuesta, además posee de un monitor para medir
entre otros datos, los tiempos de respuesta.


\section{Pruebas de Sistema}

Para poder comprobar el correcto funcionamiento de la plataforma web,
se carga una encuesta compleja, concretamente la del experimento \emph{\textquotedbl{}¿Cómo
son nuestros voluntarios?\textquotedbl{}.}

Una vez cargado dicha encuesta, se utiliza la herramienta JMeter,
para simular las acciones que realiza un voluntario al contestar una
encuesta, cometiendo todo tipo de errores posibles y asegurandonos
que los datos recibidos son los esperados.

Además de la automatización de esta prueba con JMeter, distintas personas
usaron a su antojo la plataforma web y completaron el experimento
para comprobar su correcto funcionamiento.
